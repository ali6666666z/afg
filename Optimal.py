import streamlit as st
import os
from langchain_groq import ChatGroq
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_retrieval_chain
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.memory import ConversationBufferMemory
from streamlit_mic_recorder import speech_to_text  # Import speech-to-text function
import fitz  # PyMuPDF for capturing screenshots
import pdfplumber  # For searching text in PDF

# Initialize API key variables
groq_api_key = "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"
google_api_key = "AIzaSyDdAiOdIa2I28sphYw36Genb4D--2IN1tU"

# ØªØ­Ø¯ÙŠØ« Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="BGC ChatBot",
    page_icon="BGC Logo Colored.svg",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ø¥Ø¶Ø§ÙØ© CSS Ù…Ø®ØµØµ
st.markdown("""
    <style>
        /* Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ø´Ø±ÙƒØ© ØºØ§Ø² Ø§Ù„Ø¨ØµØ±Ø© */
        :root {
            --bgc-blue: #0066B3;
            --bgc-light-blue: #00A0DC;
            --bgc-dark: #1A1A1A;
            --bgc-light: #FFFFFF;
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ */
        .main-header {
            background: linear-gradient(90deg, var(--bgc-blue) 0%, var(--bgc-light-blue) 100%);
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            color: white;
            text-align: center;
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ */
        .css-1d391kg {
            background-color: var(--bgc-dark);
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
        .stButton>button {
            background-color: var(--bgc-blue);
            color: white;
            border: none;
            border-radius: 5px;
            padding: 0.5rem 1rem;
            transition: all 0.3s ease;
        }
        .stButton>button:hover {
            background-color: var(--bgc-light-blue);
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© */
        .stChatMessage {
            border-radius: 10px;
            margin: 0.5rem 0;
            padding: 1rem;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ */
        .stChatInput {
            border: 2px solid var(--bgc-blue);
            border-radius: 5px;
            padding: 0.5rem;
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· */
        a {
            color: var(--bgc-blue);
            text-decoration: none;
        }
        a:hover {
            color: var(--bgc-light-blue);
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª */
        .info-card {
            background-color: white;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin: 1rem 0;
        }

        /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª */
        .icon-container {
            display: flex;
            justify-content: center;
            align-items: center;
            width: 50px;
            height: 50px;
            background-color: var(--bgc-blue);
            border-radius: 50%;
            margin: 0 auto 1rem auto;
        }
    </style>
""", unsafe_allow_html=True)

# ØªØ­Ø¯ÙŠØ« ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def render_main_header():
    st.markdown("""
        <div class="main-header">
            <h1>POWERING PROGRESS IN IRAQ</h1>
            <p>Basrah Gas Company ChatBot - Your Intelligent Assistant</p>
        </div>
    """, unsafe_allow_html=True)

# ØªØ­Ø¯ÙŠØ« ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
def render_sidebar():
    with st.sidebar:
        st.image("BGC Logo Colored.svg", width=150)
        st.markdown("---")
        
        # Ù‚Ø³Ù… Ø§Ù„Ù„ØºØ©
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        interface_language = st.selectbox(
            "Language | Ø§Ù„Ù„ØºØ©",
            ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"],
            index=0 if interface_language == "English" else 1
        )
        st.markdown('</div>', unsafe_allow_html=True)
        
        # Ù‚Ø³Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        st.markdown('<div class="info-card">', unsafe_allow_html=True)
        if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            st.markdown("### Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        else:
            st.markdown("### Settings")
        toggle_dark_mode()
        st.markdown('</div>', unsafe_allow_html=True)

# ØªØ­Ø¯ÙŠØ« Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
def display_message(message):
    with st.chat_message(message["role"]):
        st.markdown(f'<div class="message-content">{message["content"]}</div>', unsafe_allow_html=True)

# Initialize the PDFSearchAndDisplay class with the default PDF file
pdf_path = "BGC.pdf"
pdf_searcher = PDFSearchAndDisplay()

# Function to apply CSS based on language direction
def apply_css_direction(direction):
    st.markdown(
        f"""
        <style>
            .stApp {{
                direction: {direction};
                text-align: {direction};
            }}
            .stChatInput {{
                direction: {direction};
            }}
            .stChatMessage {{
                direction: {direction};
                text-align: {direction};
            }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# PDF Search and Screenshot Class
class PDFSearchAndDisplay:
    def __init__(self):
        pass

    def search_and_highlight(self, pdf_path, search_term):
        highlighted_pages = []
        with pdfplumber.open(pdf_path) as pdf:
            for page_number, page in enumerate(pdf.pages):
                text = page.extract_text()
                if search_term in text:
                    highlighted_pages.append((page_number, text))
        return highlighted_pages

    def capture_screenshots(self, pdf_path, pages):
        doc = fitz.open(pdf_path)
        screenshots = []
        for page_number, _ in pages:
            page = doc.load_page(page_number)
            pix = page.get_pixmap()
            screenshot_path = f"screenshot_page_{page_number}.png"
            pix.save(screenshot_path)
            screenshots.append(screenshot_path)
        return screenshots

# Validate API key inputs and initialize components if valid
if groq_api_key and google_api_key:
    # Set Google API key as environment variable
    os.environ["GOOGLE_API_KEY"] = google_api_key

    # Initialize ChatGroq with the provided Groq API key
    llm = ChatGroq(groq_api_key=groq_api_key, model_name="gemma2-9b-it")

    # Define the chat prompt template with memory
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
        You are a helpful assistant for Basrah Gas Company (BGC). Your task is to answer questions based on the provided context about BGC. Follow these rules strictly:

        1. **Language Handling:**
           - If the question is in English, answer in English.
           - If the question is in Arabic, answer in Arabic.
           - If the user explicitly asks for a response in a specific language, respond in that language.

        2. **Contextual Answers:**
           - Provide accurate and concise answers based on the context provided.
           - Do not explicitly mention the source of information unless asked.

        3. **Handling Unclear or Unanswerable Questions:**
           - If the question is unclear or lacks sufficient context, respond with:
             - In English: "I'm sorry, I couldn't understand your question. Could you please provide more details?"
             - In Arabic: "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŸ"
           - If the question cannot be answered based on the provided context, respond with:
             - In English: "I'm sorry, I don't have enough information to answer that question."
             - In Arabic: "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."

        4. **User Interface Language:**
           - If the user has selected Arabic as the interface language, prioritize Arabic in your responses unless the question is explicitly in English.
           - If the user has selected English as the interface language, prioritize English in your responses unless the question is explicitly in Arabic.

        5. **Professional Tone:**
           - Maintain a professional and respectful tone in all responses.
           - Avoid making assumptions or providing speculative answers.
        """),
        MessagesPlaceholder(variable_name="history"),  # Add chat history to the prompt
        ("human", "{input}"),
        ("system", "Context: {context}"),
    ])

    # Load existing embeddings from files
    if "vectors" not in st.session_state:
        with st.spinner("Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠØ¯Ø§Øª... Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Loading embeddings... Please wait."):
            # Initialize embeddings
            embeddings = GoogleGenerativeAIEmbeddings(
                model="models/embedding-001"
            )

            # Load existing FAISS index with safe deserialization
            embeddings_path = "embeddings"  # Path to your embeddings folder
            try:
                st.session_state.vectors = FAISS.load_local(
                    embeddings_path,
                    embeddings,
                    allow_dangerous_deserialization=True  # Only use if you trust the source of the embeddings
                )
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠØ¯Ø§Øª: {str(e)}" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else f"Error loading embeddings: {str(e)}")
                st.session_state.vectors = None

    # Microphone button in the sidebar
    st.markdown("### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "### Voice Input")
    input_lang_code = "ar" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "en"  # Set language code based on interface language
    voice_input = speech_to_text(
        start_prompt="ğŸ¤",
        stop_prompt="â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "â¹ï¸ Stop",
        language=input_lang_code,  # Language (en for English, ar for Arabic)
        use_container_width=True,
        just_once=True,
        key="mic_button",
    )

    # Reset button in the sidebar
    if st.button("Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Reset Chat"):
        st.session_state.messages = []  # Clear chat history
        st.session_state.memory.clear()  # Clear memory
        st.success("ØªÙ…Øª Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¨Ù†Ø¬Ø§Ø­." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Chat has been reset successfully.")
        st.rerun()  # Rerun the app to reflect changes immediately
else:
    st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØ§ØªÙŠØ­ API Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Please enter both API keys to proceed.")

# Initialize session state for chat messages if not already done
if "messages" not in st.session_state:
    st.session_state.messages = []

# Initialize memory if not already done
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="history",
        return_messages=True
    )

# List of negative phrases to check for unclear or insufficient answers
negative_phrases = [
    "I'm sorry",
    "Ø¹Ø°Ø±Ù‹Ø§",
    "Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©",
    "I don't have enough information",
    "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ",
    "I couldn't understand your question",
    "Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„",
    "I cannot answer this question",
    "ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„",
    "Please provide more details",
    "ØºÙŠØ± ÙˆØ§Ø¶Ø­",
    "Unclear",
    "ØºÙŠØ± Ù…ØªØ£ÙƒØ¯",
    "Not sure",
    "Ù„Ø§ Ø£Ø¹Ø±Ù",
    "I don't know",
    "ØºÙŠØ± Ù…ØªØ§Ø­",
    "Not available",
    "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
    "Not found",
    "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
    "Unknown",
    "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
    "Unspecified",
    "ØºÙŠØ± Ù…Ø¤ÙƒØ¯",
    "Uncertain",
    "ØºÙŠØ± ÙƒØ§ÙÙŠ",
    "Insufficient",
    "ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚",
    "Inaccurate",
    "ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…",
    "Not clear",
    "ØºÙŠØ± Ù…ÙƒØªÙ…Ù„",
    "Incomplete",
    "ØºÙŠØ± ØµØ­ÙŠØ­",
    "Incorrect",
    "ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨",
    "Inappropriate",
    "Please provide me",  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
    "ÙŠØ±Ø¬Ù‰ ØªØ²ÙˆÙŠØ¯ÙŠ",  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
    "Can you provide more",  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
    "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯"  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
]

# Function to display response with references and screenshots
def display_response_with_references(response, assistant_response):
    """Ø¹Ø±Ø¶ Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØµÙˆØ±"""
    with st.chat_message("assistant"):
        # Ø¹Ø±Ø¶ Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
        st.markdown(assistant_response)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØµÙˆØ± Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø±Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø¨Ø§Ø±Ø§Øª Ø³Ù„Ø¨ÙŠØ©
        if not any(phrase in assistant_response for phrase in negative_phrases):
            st.markdown("---")  # Ø®Ø· ÙØ§ØµÙ„
            if "context" in response:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ÙØ±ÙŠÙ‚Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
                page_numbers = set()
                for doc in response["context"]:
                    page_number = doc.metadata.get("page", "unknown")
                    if page_number != "unknown" and str(page_number).isdigit():
                        page_numbers.add(int(page_number))

                # Ø¹Ø±Ø¶ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª
                if page_numbers:
                    sorted_pages = sorted(page_numbers)
                    page_numbers_str = ", ".join(map(str, sorted_pages))
                    st.markdown(
                        f"**{'Ø§Ù„Ù…ØµØ¯Ø±' if interface_language == 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Source'}:** " +
                        f"{'ØµÙØ­Ø© Ø±Ù‚Ù…' if interface_language == 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Page'} {page_numbers_str}"
                    )

                    # Ø§Ù„ØªÙ‚Ø§Ø· ÙˆØ¹Ø±Ø¶ Ù„Ù‚Ø·Ø§Øª Ø§Ù„Ø´Ø§Ø´Ø© Ù„Ù„ØµÙØ­Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
                    screenshots = []
                    for page_num in sorted_pages:
                        highlighted_pages = [(page_num, "")]
                        page_screenshots = pdf_searcher.capture_screenshots(pdf_path, highlighted_pages)
                        screenshots.extend(page_screenshots)
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø´Ø¨ÙƒØ©
                    if screenshots:
                        cols = st.columns(min(len(screenshots), 2))  # Ø¹Ø±Ø¶ ØµÙˆØ±ØªÙŠÙ† ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ ÙÙŠ ÙƒÙ„ ØµÙ
                        for idx, (screenshot, page_num) in enumerate(zip(screenshots, sorted_pages)):
                            with cols[idx % 2]:
                                st.image(
                                    screenshot,
                                    caption=f"{'ØµÙØ­Ø©' if interface_language == 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Page'} {page_num}",
                                    use_container_width=True
                                )

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# If voice input is detected, process it
if voice_input:
    st.session_state.messages.append({"role": "user", "content": voice_input})
    with st.chat_message("user"):
        st.markdown(voice_input)

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        # Create and configure the document chain and retriever
        document_chain = create_stuff_documents_chain(llm, prompt)
        retriever = st.session_state.vectors.as_retriever()
        retrieval_chain = create_retrieval_chain(retriever, document_chain)

        # Get response from the assistant
        response = retrieval_chain.invoke({
            "input": voice_input,
            "context": retriever.get_relevant_documents(voice_input),
            "history": st.session_state.memory.chat_memory.messages  # Include chat history
        })
        assistant_response = response["answer"]

        # Use the new function to display the response with references
        display_response_with_references(response, assistant_response)
        
        # Save messages to memory
        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        st.session_state.memory.chat_memory.add_user_message(voice_input)
        st.session_state.memory.chat_memory.add_ai_message(assistant_response)

# Text input field
if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
    human_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")
else:
    human_input = st.chat_input("Type your question here...")

# If text input is detected, process it
if human_input:
    st.session_state.messages.append({"role": "user", "content": human_input})
    with st.chat_message("user"):
        st.markdown(human_input)

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        # Create and configure the document chain and retriever
        document_chain = create_stuff_documents_chain(llm, prompt)
        retriever = st.session_state.vectors.as_retriever()
        retrieval_chain = create_retrieval_chain(retriever, document_chain)

        # Get response from the assistant
        response = retrieval_chain.invoke({
            "input": human_input,
            "context": retriever.get_relevant_documents(human_input),
            "history": st.session_state.memory.chat_memory.messages  # Include chat history
        })
        assistant_response = response["answer"]

        # Use the new function to display the response with references
        display_response_with_references(response, assistant_response)
        
        # Save messages to memory
        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        st.session_state.memory.chat_memory.add_user_message(human_input)
        st.session_state.memory.chat_memory.add_ai_message(assistant_response)

# ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def main():
    render_main_header()
    render_sidebar()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    if not st.session_state.is_authenticated:
        render_auth_interface()
    else:
        # Ø¹Ø±Ø¶ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
        cols = st.columns([2, 1])
        with cols[0]:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for message in st.session_state.messages:
                display_message(message)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with cols[1]:
            st.markdown('<div class="info-card">', unsafe_allow_html=True)
            if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                st.markdown("### Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø³Ø±ÙŠØ¹Ø©")
                st.markdown("- Ø§Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„ØªÙƒ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
                st.markdown("- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù„Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ")
                st.markdown("- Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¨Ø¯Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©")
            else:
                st.markdown("### Quick Info")
                st.markdown("- Ask questions in Arabic or English")
                st.markdown("- Use the microphone for voice input")
                st.markdown("- Click New Chat to start a fresh conversation")
            st.markdown('</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()Ø³
