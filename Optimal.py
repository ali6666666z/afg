import os
import streamlit as st
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from streamlit_mic_recorder import speech_to_text  # Import speech-to-text function
import fitz  # PyMuPDF for capturing screenshots
import pdfplumber  # For searching text in PDF

# Initialize API key variables
groq_api_key = "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"
google_api_key = "AIzaSyDdAiOdIa2I28sphYw36Genb4D--2IN1tU"

# Change the page title and icon
st.set_page_config(
    page_title="BGC ChatBot",  # Page title
    page_icon="BGC Logo Colored.svg",  # New page icon
    layout="wide"  # Page layout
)

# Function to apply CSS based on language direction
def apply_css_direction(direction):
    st.markdown(
        f"""
        <style>
            .stApp {{
                direction: {direction};
                text-align: {direction};
            }}
            .stChatInput {{
                direction: {direction};
            }}
            .stChatMessage {{
                direction: {direction};
                text-align: {direction};
            }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# PDF Search and Screenshot Class
class PDFSearchAndDisplay:
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒÙ„Ø§Ø³"""
        self.fitz = fitz  # Ø§Ø³ØªØ®Ø¯Ø§Ù… fitz Ø§Ù„Ù…Ø³ØªÙˆØ±Ø¯ Ù…Ø¨Ø§Ø´Ø±Ø©
        
    def get_text_instances(self, page_text, search_text):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„ØµÙØ­Ø©"""
        instances = []
        search_text = search_text.lower()
        page_text = page_text.lower()
        
        start = 0
        while True:
            index = page_text.find(search_text, start)
            if index == -1:
                break
            instances.append((index, index + len(search_text)))
            start = index + 1
            
        return instances

    def capture_screenshots(self, pdf_path, page_info):
        """Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ± Ù„Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù…Ù† Ù…Ù„Ù PDF Ù…Ø¹ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù†Øµ
        
        Args:
            pdf_path (str): Ù…Ø³Ø§Ø± Ù…Ù„Ù PDF
            page_info (list): Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† (Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©ØŒ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³)
        """
        screenshots = []
        try:
            # ÙØªØ­ Ù…Ù„Ù PDF
            doc = self.fitz.open(pdf_path)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ ØµÙØ­Ø© Ù…Ø­Ø¯Ø¯Ø©
            for page_num, quoted_text in page_info:
                if 0 <= page_num < len(doc):
                    page = doc[page_num]
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³ ÙÙŠ Ø§Ù„ØµÙØ­Ø©
                    if quoted_text:
                        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„ØµÙØ­Ø©
                        page_text = page.get_text()
                        
                        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³
                        text_instances = self.get_text_instances(page_text, quoted_text)
                        
                        # ØªÙ…ÙŠÙŠØ² ÙƒÙ„ Ù…ÙˆØ¶Ø¹ Ù„Ù„Ù†Øµ
                        for start, end in text_instances:
                            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ù†Øµ Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø©
                            text_instances = page.search_for(quoted_text)
                            
                            # Ø¥Ø¶Ø§ÙØ© ØªÙ…ÙŠÙŠØ² Ù„ÙƒÙ„ Ù…ÙˆØ¶Ø¹
                            for inst in text_instances:
                                highlight = page.add_highlight_annot(inst)
                                highlight.set_colors({"stroke": (1, 1, 0)})  # Ù„ÙˆÙ† Ø£ØµÙØ± Ù„Ù„ØªÙ…ÙŠÙŠØ²
                                highlight.update()
                    
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
                    zoom = 2  # Ù…Ø¶Ø§Ø¹ÙØ© Ø§Ù„Ø¯Ù‚Ø©
                    mat = fitz.Matrix(zoom, zoom)
                    pix = page.get_pixmap(matrix=mat)
                    
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø¨Ø§ÙŠØªØ³
                    img_bytes = pix.tobytes()
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
                    screenshots.append(img_bytes)
            
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ù„Ù
            doc.close()
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF: {str(e)}")
            
        return screenshots

    def search_and_highlight(self, pdf_path, search_term):
        highlighted_pages = []
        with pdfplumber.open(pdf_path) as pdf:
            for page_number, page in enumerate(pdf.pages):
                text = page.extract_text()
                if search_term in text:
                    highlighted_pages.append((page_number, text))
        return highlighted_pages

# Sidebar configuration
with st.sidebar:
    # Language selection dropdown
    interface_language = st.selectbox("Interface Language", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])

    # Apply CSS direction based on selected language
    if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        apply_css_direction("rtl")  # Right-to-left for Arabic
        st.title("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")  # Sidebar title in Arabic
    else:
        apply_css_direction("ltr")  # Left-to-right for English
        st.title("Settings")  # Sidebar title in English

    # Validate API key inputs and initialize components if valid
    if groq_api_key and google_api_key:
        # Set Google API key as environment variable
        os.environ["GOOGLE_API_KEY"] = google_api_key

        # Initialize ChatGroq with the provided Groq API key
        llm = ChatGroq(groq_api_key=groq_api_key, model_name="gemma2-9b-it")

        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©
        def create_chat_prompt():
            return PromptTemplate(
                template="""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± Ù„Ø´Ø±ÙƒØ© ØºØ§Ø² Ø§Ù„Ø¨ØµØ±Ø© (BGC). Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©. Ø§ØªØ¨Ø¹ Ù‡Ø°Ù‡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø¯Ù‚Ø©:

1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚:
   - Ø§Ù‚Ø±Ø£ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù… Ø¨Ø¹Ù†Ø§ÙŠØ©
   - Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„
   - ØªØ£ÙƒØ¯ Ù…Ù† ÙÙ‡Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©

2. ØµÙŠØ§ØºØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
   - Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ© ÙˆØµÙ„Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„
   - Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…Ø«Ø¨ØªØ© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
   - Ù†Ø¸Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø·Ù‚ÙŠ ÙˆÙ…ØªØ³Ù„Ø³Ù„
   - Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ù‡Ù†ÙŠØ©

3. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©:
   - ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆØªØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø³Ø¤Ø§Ù„
   - ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªÙ†Ø§Ù‚Ø¶Ø©
   - Ø£Ø¶Ù ØªÙØ§ØµÙŠÙ„ Ø¯Ø§Ø¹Ù…Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…:
{context}

Ø§Ù„Ø³Ø¤Ø§Ù„: {input}

Ù‚Ù… Ø¨ØµÙŠØ§ØºØ© Ø¥Ø¬Ø§Ø¨Ø©:
1. Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆØ´Ø§Ù…Ù„Ø©
2. Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø§Ù„Ø£Ø¯Ù„Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
3. Ù…Ù†Ø¸Ù…Ø© ÙˆÙ…Ù‡Ù†ÙŠØ©
4. Ø³Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ù… ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚
""",
                input_variables=["context", "input"]
            )

        def create_custom_chain(llm, prompt):
            """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª"""
            return create_stuff_documents_chain(
                llm=llm,
                prompt=prompt
            )

        # Load existing embeddings from files
        if "vectors" not in st.session_state:
            with st.spinner("Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠØ¯Ø§Øª... Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Loading embeddings... Please wait."):
                # Initialize embeddings
                embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/embedding-001"
                )

                # Load existing FAISS index with safe deserialization
                embeddings_path = "embeddings"  # Path to your embeddings folder
                try:
                    st.session_state.vectors = FAISS.load_local(
                        embeddings_path,
                        embeddings,
                        allow_dangerous_deserialization=True  # Only use if you trust the source of the embeddings
                    )
                except Exception as e:
                    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠØ¯Ø§Øª: {str(e)}" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else f"Error loading embeddings: {str(e)}")
                    st.session_state.vectors = None

        # Microphone button in the sidebar
        st.markdown("### Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "### Voice Input")
        input_lang_code = "ar" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "en"  # Set language code based on interface language
        voice_input = speech_to_text(
            start_prompt="ğŸ¤",
            stop_prompt="â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "â¹ï¸ Stop",
            language=input_lang_code,  # Language (en for English, ar for Arabic)
            use_container_width=True,
            just_once=True,
            key="mic_button",
        )

        # Reset button in the sidebar
        if st.button("Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©" if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Reset Chat"):
            st.session_state.messages = []  # Clear chat history
            st.session_state.memory.clear()  # Clear memory
            st.success("ØªÙ…Øª Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø¨Ù†Ø¬Ø§Ø­." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Chat has been reset successfully.")
            st.rerun()  # Rerun the app to reflect changes immediately
    else:
        st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØ§ØªÙŠØ­ API Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Please enter both API keys to proceed.")

# Initialize the PDFSearchAndDisplay class with the default PDF file
pdf_path = "BGC.pdf"
pdf_searcher = PDFSearchAndDisplay()

# Main area for chat interface
# Use columns to display logo and title side by side
col1, col2 = st.columns([1, 4])  # Adjust the ratio as needed

# Display the logo in the first column
with col1:
    st.image("BGC Logo Colored.svg", width=100)  # Adjust the width as needed

# Display the title and description in the second column
with col2:
    if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        st.title("Ù…Ø­Ù…Ø¯ Ø§Ù„ÙŠØ§Ø³ÙŠÙ† | Ø¨ÙˆØª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© BGC")
        st.write("""
        **Ù…Ø±Ø­Ø¨Ù‹Ø§!**  
        Ù‡Ø°Ø§ Ø¨ÙˆØª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø®Ø§Øµ Ø¨Ø´Ø±ÙƒØ© ØºØ§Ø² Ø§Ù„Ø¨ØµØ±Ø© (BGC). ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ø¨ÙˆØª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ø´Ø±ÙƒØ© ÙˆØ£Ù†Ø´Ø·ØªÙ‡Ø§.  
        **ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**  
        - Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠ Ù…Ø±Ø¨Ø¹ Ø§Ù„Ù†Øµ Ø£Ø¯Ù†Ø§Ù‡.  
        - Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø§Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù„Ù„ØªØ­Ø¯Ø« Ù…Ø¨Ø§Ø´Ø±Ø©.  
        - Ø³ÙŠØªÙ… Ø§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©.  
        """)
    else:
        st.title("Mohammed Al-Yaseen | BGC ChatBot")
        st.write("""
        **Welcome!**  
        This is the Basrah Gas Company (BGC) ChatBot. You can use this bot to get information about the company and its activities.  
        **How to use:**  
        - Type your question in the text box below.  
        - Or use the microphone button to speak directly.  
        - You will receive a response based on the available information.  
        """)

# Initialize session state for chat messages if not already done
if "messages" not in st.session_state:
    st.session_state.messages = []

# Initialize memory if not already done
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="history",
        return_messages=True
    )

# List of negative phrases to check for unclear or insufficient answers
negative_phrases = [
    "I'm sorry",
    "Ø¹Ø°Ø±Ù‹Ø§",
    "Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©",
    "I don't have enough information",
    "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ",
    "I couldn't understand your question",
    "Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„",
    "I cannot answer this question",
    "ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„",
    "Please provide more details",
    "ØºÙŠØ± ÙˆØ§Ø¶Ø­",
    "Unclear",
    "ØºÙŠØ± Ù…ØªØ£ÙƒØ¯",
    "Not sure",
    "Ù„Ø§ Ø£Ø¹Ø±Ù",
    "I don't know",
    "ØºÙŠØ± Ù…ØªØ§Ø­",
    "Not available",
    "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
    "Not found",
    "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
    "Unknown",
    "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
    "Unspecified",
    "ØºÙŠØ± Ù…Ø¤ÙƒØ¯",
    "Uncertain",
    "ØºÙŠØ± ÙƒØ§ÙÙŠ",
    "Insufficient",
    "ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚",
    "Inaccurate",
    "ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…",
    "Not clear",
    "ØºÙŠØ± Ù…ÙƒØªÙ…Ù„",
    "Incomplete",
    "ØºÙŠØ± ØµØ­ÙŠØ­",
    "Incorrect",
    "ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨",
    "Inappropriate",
    "Please provide me",  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
    "ÙŠØ±Ø¬Ù‰ ØªØ²ÙˆÙŠØ¯ÙŠ",  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
    "Can you provide more",  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
    "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯"  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø©
]

def clean_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„ÙØ±Ø§ØºØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ±Ø§ØºØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = ' '.join(text.split())
    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
    text = text.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
    return text

def extract_complete_sentences(text, max_length=200):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…Ù„ ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ù†Øµ"""
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„
    sentences = text.split('.')
    complete_text = []
    current_length = 0
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¬Ù…Ù„Ø© ØªØ¨Ø¯Ø£ Ø¨Ø­Ø±Ù ÙƒØ¨ÙŠØ± ÙˆØªÙ†ØªÙ‡ÙŠ Ø¨Ù†Ù‚Ø·Ø©
        if sentence[0].isalpha():
            sentence = sentence[0].upper() + sentence[1:]
        if not sentence.endswith('.'):
            sentence += '.'
            
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ù…Ù„Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·ÙˆÙ„
        if current_length + len(sentence) <= max_length:
            complete_text.append(sentence)
            current_length += len(sentence)
        else:
            break
            
    return ' '.join(complete_text)

def get_relevant_context(retriever, query, k=5):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø© ÙˆØªÙ†Ø¸ÙŠÙ…Ù‡"""
    # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    docs = retriever.get_relevant_documents(
        query,
        search_kwargs={"k": k * 2}  # Ù…Ø¶Ø§Ø¹ÙØ© Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø£ÙØ¶Ù„
    )
    
    # ØªÙ†Ø¸ÙŠÙ… ÙˆØªÙ†Ù‚ÙŠØ© Ø§Ù„Ø³ÙŠØ§Ù‚
    organized_context = []
    total_length = 0
    max_length = 1000  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù†Øµ
    
    for doc in docs:
        text = clean_text(doc.page_content)
        complete_text = extract_complete_sentences(text, max_length=300)  # Ø²ÙŠØ§Ø¯Ø© Ø·ÙˆÙ„ Ø§Ù„Ø¬Ù…Ù„
        
        if complete_text and not any(
            similar_text(complete_text, existing.page_content) > 0.7
            for existing in organized_context
        ):
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            if total_length + len(complete_text) <= max_length:
                organized_doc = Document(
                    page_content=complete_text,
                    metadata={"page": doc.metadata.get("page", "unknown")}
                )
                organized_context.append(organized_doc)
                total_length += len(complete_text)
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
    organized_context.sort(
        key=lambda x: calculate_relevance_score(x.page_content, query),
        reverse=True
    )
    
    return organized_context[:k]

def similar_text(text1, text2):
    """Ø­Ø³Ø§Ø¨ Ù…Ø¯Ù‰ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù†ØµÙˆØµ"""
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    return len(intersection) / len(union) if union else 0

def calculate_relevance_score(text, query):
    """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø³Ø¤Ø§Ù„"""
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª
    text_words = set(text.lower().split())
    query_words = set(query.lower().split())
    
    # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
    common_words = len(text_words.intersection(query_words))
    
    # Ø­Ø³Ø§Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ (Ø¹Ù‚ÙˆØ¨Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹)
    length_penalty = 1.0 / (1.0 + len(text_words) / 100.0)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    score = common_words * length_penalty
    
    return score

def process_input(input_text, retriever, llm, memory):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª"""
    try:
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø³Ù†
        context = get_relevant_context(retriever, input_text)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨ ÙˆØ§Ù„Ø³Ù„Ø³Ù„Ø©
        prompt = create_chat_prompt()
        chain = create_retrieval_chain(
            retriever=retriever,
            combine_docs_chain=create_custom_chain(llm, prompt)
        )
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        enhanced_input = f"""
        Ø§Ù„Ø³Ø¤Ø§Ù„: {input_text}
        
        Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:
        1. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø©
        2. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù‡Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
        3. Ù†Ø¸Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø·Ù‚ÙŠ
        4. Ø§Ø°ÙƒØ± Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©
        """
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        response = chain.invoke({
            "input": enhanced_input,
            "history": memory.load_memory_variables({})["history"]
        })
        
        # ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
        organized_response = {
            "answer": response["answer"],
            "context": context
        }
        
        return organized_response
        
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„: {str(e)}")
        return None

def display_response_with_references(response_data):
    """Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØµÙˆØ±"""
    if not response_data:
        return
        
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
    if isinstance(response_data, dict):
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ 'answer'
        if "answer" in response_data:
            st.write(response_data["answer"])
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ 'content'
        elif "content" in response_data:
            st.write(response_data["content"])
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙØ­Ø§Øª
        context_data = None
        if "context" in response_data:
            context_data = response_data["context"]
        elif "references" in response_data and isinstance(response_data["references"], dict):
            context_data = response_data["references"].get("context")
        
        if context_data:
            st.markdown("### Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©")
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØµÙØ­Ø§Øª
            images_data = []
            for doc in context_data:
                page_num = doc.metadata.get("page", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
                try:
                    # Ø§Ù„ØªÙ‚Ø§Ø· Ù„Ù‚Ø·Ø© Ù…Ù† Ø§Ù„ØµÙØ­Ø©
                    image = pdf_searcher.capture_screenshots(pdf_path, [(page_num, doc.page_content)])[0]
                    if image:
                        images_data.append((image, page_num))
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙØ­Ø© {page_num}: {str(e)}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø´Ø¨ÙƒØ©
            if images_data:
                cols = st.columns(2)  # Ø¹Ø±Ø¶ ØµÙˆØ±ØªÙŠÙ† ÙÙŠ ÙƒÙ„ ØµÙ
                for idx, (image, page_num) in enumerate(images_data):
                    with cols[idx % 2]:
                        st.image(image)
                        st.markdown(f"**ØµÙØ­Ø© {page_num}**", help="Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯")
    else:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ Ù†ØµØ§Ù‹ Ø¹Ø§Ø¯ÙŠØ§Ù‹
        st.write(response_data)

# Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state.messages:
    if message["role"] == "assistant" and "references" in message:
        display_response_with_references(message["references"])
    else:
        st.write(message["content"])

# Ø­Ù‚Ù„ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ
if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
    human_input = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")
else:
    human_input = st.text_input("Type your question here...")

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†ØµÙŠ
if human_input:
    user_message = {"role": "user", "content": human_input}
    st.session_state.messages.append(user_message)
    st.write(user_message["content"])

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            response = process_input(
                human_input,
                st.session_state.vectors.as_retriever(),
                llm,
                st.session_state.memory
            )
            
            if response:
                assistant_message = {
                    "role": "assistant",
                    "content": response["answer"],
                    "references": response
                }
                st.session_state.messages.append(assistant_message)
                st.session_state.memory.chat_memory.add_user_message(human_input)
                st.session_state.memory.chat_memory.add_ai_message(response["answer"])

                # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¯ Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØµÙˆØ±
                display_response_with_references(response)
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©
if voice_input:
    user_message = {"role": "user", "content": voice_input}
    st.session_state.messages.append(user_message)
    st.write(user_message["content"])

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        try:
            response = process_input(
                voice_input,
                st.session_state.vectors.as_retriever(),
                llm,
                st.session_state.memory
            )
            
            if response:
                assistant_message = {
                    "role": "assistant",
                    "content": response["answer"],
                    "references": response
                }
                st.session_state.messages.append(assistant_message)
                st.session_state.memory.chat_memory.add_user_message(voice_input)
                st.session_state.memory.chat_memory.add_ai_message(response["answer"])

                # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¯ Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØµÙˆØ±
                display_response_with_references(response)
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
