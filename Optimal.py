import os
import streamlit as st
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from streamlit_mic_recorder import speech_to_text  # Import speech-to-text function
import fitz  # PyMuPDF for capturing screenshots
import pdfplumber  # For searching text in PDF

# Initialize API key variables
groq_api_key = "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"
google_api_key = "AIzaSyDdAiOdIa2I28sphYw36Genb4D--2IN1tU"

# Change the page title and icon
st.set_page_config(
    page_title="BGC ChatBot",  # Page title
    page_icon="BGC Logo Colored.svg",  # New page icon
    layout="wide"  # Page layout
)

# Function to apply CSS based on language direction
def apply_css_direction(direction):
    st.markdown(
        f"""
        <style>
            .stApp {{
                direction: {direction};
                text-align: {direction};
            }}
            .stChatInput {{
                direction: {direction};
            }}
            .stChatMessage {{
                direction: {direction};
                text-align: {direction};
            }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# PDF Search and Screenshot Class
class PDFSearchAndDisplay:
    def __init__(self):
        """ÿ™ŸáŸäÿ¶ÿ© ÿßŸÑŸÉŸÑÿßÿ≥"""
        self.fitz = fitz
        self.pdfplumber = pdfplumber

    def capture_screenshots(self, pdf_path, pages):
        """ÿßŸÑÿ™ŸÇÿßÿ∑ ÿµŸàÿ± ŸÖŸÜ ÿµŸÅÿ≠ÿßÿ™ PDF ŸÖÿ≠ÿØÿØÿ©"""
        screenshots = []
        try:
            doc = self.fitz.open(pdf_path)
            for page_num, _ in pages:
                if 0 <= page_num < len(doc):
                    page = doc[page_num]
                    # ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑÿµŸÅÿ≠ÿ© ÿ•ŸÑŸâ ÿµŸàÿ±ÿ© ÿ®ÿØŸÇÿ© ÿπÿßŸÑŸäÿ©
                    zoom = 2
                    mat = fitz.Matrix(zoom, zoom)
                    pix = page.get_pixmap(matrix=mat)
                    screenshots.append(pix.tobytes())
            doc.close()
        except Exception as e:
            st.error(f"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ŸÖÿπÿßŸÑÿ¨ÿ© ŸÖŸÑŸÅ PDF: {str(e)}")
        return screenshots

# Sidebar configuration
with st.sidebar:
    # Language selection dropdown
    interface_language = st.selectbox("Interface Language", ["English", "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©"])

    # Apply CSS direction based on selected language
    if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©":
        apply_css_direction("rtl")  # Right-to-left for Arabic
        st.title("ÿßŸÑÿ•ÿπÿØÿßÿØÿßÿ™")  # Sidebar title in Arabic
    else:
        apply_css_direction("ltr")  # Left-to-right for English
        st.title("Settings")  # Sidebar title in English

    # Validate API key inputs and initialize components if valid
    if groq_api_key and google_api_key:
        # Set Google API key as environment variable
        os.environ["GOOGLE_API_KEY"] = google_api_key

        # Initialize ChatGroq with the provided Groq API key
        llm = ChatGroq(groq_api_key=groq_api_key, model_name="gemma2-9b-it")

        # ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÇÿßŸÑÿ® ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿä ŸÑŸÑÿØÿ±ÿØÿ¥ÿ©
        def create_chat_prompt():
            return PromptTemplate(
                template="""ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ŸÖŸÅŸäÿØ ŸÑÿ¥ÿ±ŸÉÿ© ÿ∫ÿßÿ≤ ÿßŸÑÿ®ÿµÿ±ÿ© (BGC). ŸÖŸáŸÖÿ™ŸÉ ŸáŸä ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿπŸÑŸâ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖŸÇÿØŸÖ ÿ≠ŸàŸÑ BGC. ÿßÿ™ÿ®ÿπ Ÿáÿ∞Ÿá ÿßŸÑŸÇŸàÿßÿπÿØ ÿ®ÿØŸÇÿ©:

                1. ŸÇÿØŸÖ ÿ•ÿ¨ÿßÿ®ÿßÿ™ ÿØŸÇŸäŸÇÿ© ŸàŸÖÿ®ÿßÿ¥ÿ±ÿ©
                2. ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÖŸÜ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖŸÇÿØŸÖ
                3. ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ŸÉŸÜ ŸÖÿ™ÿ£ŸÉÿØÿßŸãÿå ŸÇŸÑ ÿ∞ŸÑŸÉ ÿ®ÿµÿ±ÿßÿ≠ÿ©
                4. ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ŸÑÿ∫ÿ© ŸÖŸáŸÜŸäÿ© ŸàŸÖÿ≠ÿ™ÿ±ŸÅÿ©

                ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖŸÇÿØŸÖ:
                {context}

                ÿßŸÑÿ≥ÿ§ÿßŸÑ: {input}

                ÿ™ÿ∞ŸÉÿ± ÿ£ŸÜ ÿ™ŸÇÿØŸÖ ÿ•ÿ¨ÿßÿ®ÿ©:
                1. ÿØŸÇŸäŸÇÿ© ŸàŸÖÿ≥ÿ™ŸÜÿØÿ© ÿ•ŸÑŸâ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ
                2. ŸÖÿ®ÿßÿ¥ÿ±ÿ© ŸàŸàÿßÿ∂ÿ≠ÿ©
                3. ŸÖŸáŸÜŸäÿ© ŸàŸÖŸÜÿ∏ŸÖÿ©
                """,
                input_variables=["context", "input"]
            )

        def create_custom_chain(llm, prompt):
            """ÿ•ŸÜÿ¥ÿßÿ° ÿ≥ŸÑÿ≥ŸÑÿ© ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™"""
            return create_stuff_documents_chain(
                llm=llm,
                prompt=prompt
            )

        # Load existing embeddings from files
        if "vectors" not in st.session_state:
            with st.spinner("ÿ¨ÿßÿ±Ÿç ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ™ÿ∂ŸÖŸäÿØÿßÿ™... ÿßŸÑÿ±ÿ¨ÿßÿ° ÿßŸÑÿßŸÜÿ™ÿ∏ÿßÿ±." if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "Loading embeddings... Please wait."):
                # Initialize embeddings
                embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/embedding-001"
                )

                # Load existing FAISS index with safe deserialization
                embeddings_path = "embeddings"  # Path to your embeddings folder
                try:
                    st.session_state.vectors = FAISS.load_local(
                        embeddings_path,
                        embeddings,
                        allow_dangerous_deserialization=True  # Only use if you trust the source of the embeddings
                    )
                except Exception as e:
                    st.error(f"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ™ÿ∂ŸÖŸäÿØÿßÿ™: {str(e)}" if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else f"Error loading embeddings: {str(e)}")
                    st.session_state.vectors = None

        # Microphone button in the sidebar
        st.markdown("### ÿßŸÑÿ•ÿØÿÆÿßŸÑ ÿßŸÑÿµŸàÿ™Ÿä" if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "### Voice Input")
        input_lang_code = "ar" if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "en"  # Set language code based on interface language
        voice_input = speech_to_text(
            start_prompt="üé§",
            stop_prompt="‚èπÔ∏è ÿ•ŸäŸÇÿßŸÅ" if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "‚èπÔ∏è Stop",
            language=input_lang_code,  # Language (en for English, ar for Arabic)
            use_container_width=True,
            just_once=True,
            key="mic_button",
        )

        # Reset button in the sidebar
        if st.button("ÿ•ÿπÿßÿØÿ© ÿ™ÿπŸäŸäŸÜ ÿßŸÑÿØÿ±ÿØÿ¥ÿ©" if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "Reset Chat"):
            st.session_state.messages = []  # Clear chat history
            st.session_state.memory.clear()  # Clear memory
            st.success("ÿ™ŸÖÿ™ ÿ•ÿπÿßÿØÿ© ÿ™ÿπŸäŸäŸÜ ÿßŸÑÿØÿ±ÿØÿ¥ÿ© ÿ®ŸÜÿ¨ÿßÿ≠." if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "Chat has been reset successfully.")
            st.rerun()  # Rerun the app to reflect changes immediately
    else:
        st.error("ÿßŸÑÿ±ÿ¨ÿßÿ° ÿ•ÿØÿÆÿßŸÑ ŸÖŸÅÿßÿ™Ÿäÿ≠ API ŸÑŸÑŸÖÿ™ÿßÿ®ÿπÿ©." if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©" else "Please enter both API keys to proceed.")

# Initialize the PDFSearchAndDisplay class with the default PDF file
pdf_path = "BGC.pdf"
pdf_searcher = PDFSearchAndDisplay()

# Main area for chat interface
# Use columns to display logo and title side by side
col1, col2 = st.columns([1, 4])  # Adjust the ratio as needed

# Display the logo in the first column
with col1:
    st.image("BGC Logo Colored.svg", width=100)  # Adjust the width as needed

# Display the title and description in the second column
with col2:
    if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©":
        st.title("ŸÖÿ≠ŸÖÿØ ÿßŸÑŸäÿßÿ≥ŸäŸÜ | ÿ®Ÿàÿ™ ÿßŸÑÿØÿ±ÿØÿ¥ÿ© BGC")
        st.write("""
        **ŸÖÿ±ÿ≠ÿ®Ÿãÿß!**  
        Ÿáÿ∞ÿß ÿ®Ÿàÿ™ ÿßŸÑÿØÿ±ÿØÿ¥ÿ© ÿßŸÑÿÆÿßÿµ ÿ®ÿ¥ÿ±ŸÉÿ© ÿ∫ÿßÿ≤ ÿßŸÑÿ®ÿµÿ±ÿ© (BGC). ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Ÿáÿ∞ÿß ÿßŸÑÿ®Ÿàÿ™ ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ≠ŸàŸÑ ÿßŸÑÿ¥ÿ±ŸÉÿ© Ÿàÿ£ŸÜÿ¥ÿ∑ÿ™Ÿáÿß.  
        **ŸÉŸäŸÅŸäÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**  
        - ÿßŸÉÿ™ÿ® ÿ≥ÿ§ÿßŸÑŸÉ ŸÅŸä ŸÖÿ±ÿ®ÿπ ÿßŸÑŸÜÿµ ÿ£ÿØŸÜÿßŸá.  
        - ÿ£Ÿà ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ≤ÿ± ÿßŸÑŸÖÿßŸäŸÉÿ±ŸàŸÅŸàŸÜ ŸÑŸÑÿ™ÿ≠ÿØÿ´ ŸÖÿ®ÿßÿ¥ÿ±ÿ©.  
        - ÿ≥Ÿäÿ™ŸÖ ÿßŸÑÿ±ÿØ ÿπŸÑŸäŸÉ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©.  
        """)
    else:
        st.title("Mohammed Al-Yaseen | BGC ChatBot")
        st.write("""
        **Welcome!**  
        This is the Basrah Gas Company (BGC) ChatBot. You can use this bot to get information about the company and its activities.  
        **How to use:**  
        - Type your question in the text box below.  
        - Or use the microphone button to speak directly.  
        - You will receive a response based on the available information.  
        """)

# Initialize session state for chat messages if not already done
if "messages" not in st.session_state:
    st.session_state.messages = []

# Initialize memory if not already done
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="history",
        return_messages=True
    )

# List of negative phrases to check for unclear or insufficient answers
negative_phrases = [
    "I'm sorry",
    "ÿπÿ∞ÿ±Ÿãÿß",
    "ŸÑÿß ÿ£ŸÖŸÑŸÉ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉÿßŸÅŸäÿ©",
    "I don't have enough information",
    "ŸÑŸÖ ÿ£ÿ™ŸÖŸÉŸÜ ŸÖŸÜ ŸÅŸáŸÖ ÿ≥ÿ§ÿßŸÑŸÉ",
    "I couldn't understand your question",
    "ŸÑÿß ŸäŸÖŸÉŸÜŸÜŸä ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿπŸÑŸâ Ÿáÿ∞ÿß ÿßŸÑÿ≥ÿ§ÿßŸÑ",
    "I cannot answer this question",
    "Ÿäÿ±ÿ¨Ÿâ ÿ™ŸÇÿØŸäŸÖ ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ",
    "Please provide more details",
    "ÿ∫Ÿäÿ± Ÿàÿßÿ∂ÿ≠",
    "Unclear",
    "ÿ∫Ÿäÿ± ŸÖÿ™ÿ£ŸÉÿØ",
    "Not sure",
    "ŸÑÿß ÿ£ÿπÿ±ŸÅ",
    "I don't know",
    "ÿ∫Ÿäÿ± ŸÖÿ™ÿßÿ≠",
    "Not available",
    "ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØ",
    "Not found",
    "ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ",
    "Unknown",
    "ÿ∫Ÿäÿ± ŸÖÿ≠ÿØÿØ",
    "Unspecified",
    "ÿ∫Ÿäÿ± ŸÖÿ§ŸÉÿØ",
    "Uncertain",
    "ÿ∫Ÿäÿ± ŸÉÿßŸÅŸä",
    "Insufficient",
    "ÿ∫Ÿäÿ± ÿØŸÇŸäŸÇ",
    "Inaccurate",
    "ÿ∫Ÿäÿ± ŸÖŸÅŸáŸàŸÖ",
    "Not clear",
    "ÿ∫Ÿäÿ± ŸÖŸÉÿ™ŸÖŸÑ",
    "Incomplete",
    "ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠",
    "Incorrect",
    "ÿ∫Ÿäÿ± ŸÖŸÜÿßÿ≥ÿ®",
    "Inappropriate",
    "Please provide me",  # ÿ•ÿ∂ÿßŸÅÿ© Ÿáÿ∞Ÿá ÿßŸÑÿπÿ®ÿßÿ±ÿ©
    "Ÿäÿ±ÿ¨Ÿâ ÿ™ÿ≤ŸàŸäÿØŸä",  # ÿ•ÿ∂ÿßŸÅÿ© Ÿáÿ∞Ÿá ÿßŸÑÿπÿ®ÿßÿ±ÿ©
    "Can you provide more",  # ÿ•ÿ∂ÿßŸÅÿ© Ÿáÿ∞Ÿá ÿßŸÑÿπÿ®ÿßÿ±ÿ©
    "ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ÿ™ŸÇÿØŸäŸÖ ÿßŸÑŸÖÿ≤ŸäÿØ"  # ÿ•ÿ∂ÿßŸÅÿ© Ÿáÿ∞Ÿá ÿßŸÑÿπÿ®ÿßÿ±ÿ©
]

def clean_text(text):
    """ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÜÿµ ŸÖŸÜ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ° ŸàÿßŸÑŸÅÿ±ÿßÿ∫ÿßÿ™ ÿßŸÑÿ≤ÿßÿ¶ÿØÿ©"""
    # ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑŸÅÿ±ÿßÿ∫ÿßÿ™ ÿßŸÑÿ≤ÿßÿ¶ÿØÿ©
    text = ' '.join(text.split())
    # ÿ•ÿ≤ÿßŸÑÿ© ÿπŸÑÿßŸÖÿßÿ™ ÿßŸÑÿ™ŸÜÿ≥ŸäŸÇ ÿ∫Ÿäÿ± ÿßŸÑŸÖÿ±ÿ∫Ÿàÿ®ÿ©
    text = text.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
    return text

def extract_complete_sentences(text, max_length=200):
    """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ¨ŸÖŸÑ ŸÉÿßŸÖŸÑÿ© ŸÖŸÜ ÿßŸÑŸÜÿµ"""
    # ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ÿ¨ŸÖŸÑ
    sentences = text.split('.')
    complete_text = []
    current_length = 0
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        # ÿßŸÑÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑÿ¨ŸÖŸÑÿ© ÿ™ÿ®ÿØÿ£ ÿ®ÿ≠ÿ±ŸÅ ŸÉÿ®Ÿäÿ± Ÿàÿ™ŸÜÿ™ŸáŸä ÿ®ŸÜŸÇÿ∑ÿ©
        if sentence[0].isalpha():
            sentence = sentence[0].upper() + sentence[1:]
        if not sentence.endswith('.'):
            sentence += '.'
            
        # ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑÿ¨ŸÖŸÑÿ© ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ÿ∂ŸÖŸÜ ÿßŸÑÿ≠ÿØ ÿßŸÑÿ£ŸÇÿµŸâ ŸÑŸÑÿ∑ŸàŸÑ
        if current_length + len(sentence) <= max_length:
            complete_text.append(sentence)
            current_length += len(sentence)
        else:
            break
            
    return ' '.join(complete_text)

def get_relevant_context(retriever, query, k=3):
    """ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑÿ£ŸÉÿ´ÿ± ÿµŸÑÿ© Ÿàÿ™ŸÜÿ∏ŸäŸÖŸá"""
    # ÿßÿ≥ÿ™ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©
    docs = retriever.get_relevant_documents(query)
    
    # ÿ™ŸÜÿ∏ŸäŸÖ Ÿàÿ™ŸÜŸÇŸäÿ© ÿßŸÑÿ≥ŸäÿßŸÇ
    organized_context = []
    for doc in docs[:k]:  # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ£ŸÅÿ∂ŸÑ k ŸÖÿ≥ÿ™ŸÜÿØÿßÿ™ ŸÅŸÇÿ∑
        text = clean_text(doc.page_content)
        complete_text = extract_complete_sentences(text)
        if complete_text:
            # ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ´ŸäŸÇÿ© ÿ¨ÿØŸäÿØÿ© ŸÖÿπ ÿßŸÑŸÜÿµ ÿßŸÑŸÖŸÜÿ∏ŸÖ
            organized_doc = Document(
                page_content=complete_text,
                metadata={"page": doc.metadata.get("page", "unknown")}
            )
            organized_context.append(organized_doc)
    
    return organized_context

def process_input(input_text, retriever, llm, memory):
    """ŸÖÿπÿßŸÑÿ¨ÿ© ÿ•ÿØÿÆÿßŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿπ ÿ™ÿ≠ÿ≥ŸäŸÜ ÿ¨ŸàÿØÿ© ÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ŸàÿßŸÑÿ≥ŸäÿßŸÇ"""
    try:
        # ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖŸÜÿ∏ŸÖ
        context = get_relevant_context(retriever, input_text)
        
        # ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑŸÇÿßŸÑÿ® ŸàÿßŸÑÿ≥ŸÑÿ≥ŸÑÿ©
        prompt = create_chat_prompt()
        chain = create_retrieval_chain(
            retriever=retriever,
            combine_docs_chain=create_custom_chain(llm, prompt)
        )
        
        # ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©
        response = chain.invoke({
            "input": input_text,
            "history": memory.load_memory_variables({})["history"]
        })
        
        # ÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ŸàÿßŸÑÿ≥ŸäÿßŸÇ
        organized_response = {
            "answer": response["answer"],
            "context": context
        }
        
        return organized_response
        
    except Exception as e:
        st.error(f"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ≥ÿ§ÿßŸÑ: {str(e)}")
        return None

def display_references(refs):
    if refs and "context" in refs:
        # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ£ÿ±ŸÇÿßŸÖ ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ŸÅŸÇÿ∑
        page_info = []
        for doc in refs["context"]:
            page_number = doc.metadata.get("page", "unknown")
            if page_number != "unknown" and str(page_number).isdigit():
                page_info.append(int(page_number))

        # ÿπÿ±ÿ∂ ÿßŸÑÿµŸàÿ±
        if page_info:
            # ÿ•ŸÜÿ¥ÿßÿ° ÿπŸÖŸàÿØŸäŸÜ ŸÑÿπÿ±ÿ∂ ÿßŸÑÿµŸàÿ±
            cols = st.columns(2)
            
            # ÿßŸÑÿ™ŸÇÿßÿ∑ Ÿàÿπÿ±ÿ∂ ŸÑŸÇÿ∑ÿßÿ™ ÿßŸÑÿ¥ÿßÿ¥ÿ© ŸÑŸÑÿµŸÅÿ≠ÿßÿ™
            for idx, page_num in enumerate(sorted(set(page_info))):
                col_idx = idx % 2
                with cols[col_idx]:
                    screenshots = pdf_searcher.capture_screenshots(pdf_path, [(page_num, "")])
                    if screenshots:
                        st.image(screenshots[0], use_container_width=True)
                        st.markdown(f"**ÿµŸÅÿ≠ÿ© {page_num}**")

def display_chat_message(message, with_refs=False):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if with_refs and "references" in message:
            display_references(message["references"])

def display_response_with_references(response, assistant_response):
    if not any(phrase in assistant_response for phrase in negative_phrases):
        # ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ÿ•ŸÑŸâ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ©
        message = {
            "role": "assistant",
            "content": assistant_response,
            "references": response
        }
        display_chat_message(message, with_refs=True)
    else:
        # ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑÿ±ÿØ Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿπÿ®ÿßÿ±ÿßÿ™ ÿ≥ŸÑÿ®Ÿäÿ©ÿå ŸÜÿπÿ±ÿ∂ ÿßŸÑÿ±ÿØ ŸÅŸÇÿ∑
        display_chat_message({
            "role": "assistant",
            "content": assistant_response
        })

# ÿπÿ±ÿ∂ ÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©
for message in st.session_state.messages:
    if message["role"] == "assistant" and "references" in message:
        display_chat_message(message, with_refs=True)
    else:
        display_chat_message(message)

# ÿ≠ŸÇŸÑ ÿ•ÿØÿÆÿßŸÑ ÿßŸÑŸÜÿµ
if interface_language == "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©":
    human_input = st.chat_input("ÿßŸÉÿ™ÿ® ÿ≥ÿ§ÿßŸÑŸÉ ŸáŸÜÿß...")
else:
    human_input = st.chat_input("Type your question here...")

# ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ•ÿØÿÆÿßŸÑ ÿßŸÑŸÜÿµŸä
if human_input:
    user_message = {"role": "user", "content": human_input}
    st.session_state.messages.append(user_message)
    display_chat_message(user_message)

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        try:
            # ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ•ÿØÿÆÿßŸÑ ŸÖÿπ ÿßŸÑÿ™ÿ≠ÿ≥ŸäŸÜÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ©
            response = process_input(
                human_input,
                st.session_state.vectors.as_retriever(),
                llm,
                st.session_state.memory
            )
            
            if response:
                assistant_message = {
                    "role": "assistant",
                    "content": response["answer"],
                    "references": {"context": response["context"]}
                }
                st.session_state.messages.append(assistant_message)
                st.session_state.memory.chat_memory.add_user_message(human_input)
                st.session_state.memory.chat_memory.add_ai_message(response["answer"])

                # ÿπÿ±ÿ∂ ÿßŸÑÿ±ÿØ ŸÖÿπ ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ŸàÿßŸÑÿµŸàÿ±
                display_response_with_references(response, response["answer"])
        except Exception as e:
            st.error(f"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£: {str(e)}")

# ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ•ÿØÿÆÿßŸÑ ÿßŸÑÿµŸàÿ™Ÿä ÿ®ŸÜŸÅÿ≥ ÿßŸÑÿ∑ÿ±ŸäŸÇÿ©
if voice_input:
    user_message = {"role": "user", "content": voice_input}
    st.session_state.messages.append(user_message)
    display_chat_message(user_message)

    if "vectors" in st.session_state and st.session_state.vectors is not None:
        try:
            response = process_input(
                voice_input,
                st.session_state.vectors.as_retriever(),
                llm,
                st.session_state.memory
            )
            
            if response:
                assistant_message = {
                    "role": "assistant",
                    "content": response["answer"],
                    "references": {"context": response["context"]}
                }
                st.session_state.messages.append(assistant_message)
                st.session_state.memory.chat_memory.add_user_message(voice_input)
                st.session_state.memory.chat_memory.add_ai_message(response["answer"])

                # ÿπÿ±ÿ∂ ÿßŸÑÿ±ÿØ ŸÖÿπ ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ ŸàÿßŸÑÿµŸàÿ±
                display_response_with_references(response, response["answer"])
        except Exception as e:
            st.error(f"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£: {str(e)}")
