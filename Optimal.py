# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©
import os
import streamlit as st
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from streamlit_mic_recorder import speech_to_text
import fitz  # PyMuPDF for capturing screenshots
import pdfplumber  # For searching text in PDF

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
negative_phrases = [
    "Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ©",
    "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ÙÙ‡Ù… Ø³Ø¤Ø§Ù„Ùƒ",
    "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹",
    "I don't have enough information",
    "I couldn't understand your question",
    "I apologize, I cannot",
    "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø²ÙŠØ¯"
]

# Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ
def clean_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„ÙØ±Ø§ØºØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
    text = ' '.join(text.split())
    text = text.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
    return text

def extract_complete_sentences(text, max_length=200):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…Ù„ ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ù†Øµ"""
    sentences = text.split('.')
    complete_text = []
    current_length = 0
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        if sentence[0].isalpha():
            sentence = sentence[0].upper() + sentence[1:]
        if not sentence.endswith('.'):
            sentence += '.'
            
        if current_length + len(sentence) <= max_length:
            complete_text.append(sentence)
            current_length += len(sentence)
        else:
            break
            
    return ' '.join(complete_text)

# ÙƒÙ„Ø§Ø³ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª PDF
class PDFSearchAndDisplay:
    def __init__(self):
        self.fitz = fitz
        
    def get_text_instances(self, page_text, search_text):
        instances = []
        search_text = search_text.lower()
        page_text = page_text.lower()
        
        start = 0
        while True:
            index = page_text.find(search_text, start)
            if index == -1:
                break
            instances.append((index, index + len(search_text)))
            start = index + 1
            
        return instances

    def capture_screenshots(self, pdf_path, page_info):
        screenshots = []
        try:
            doc = self.fitz.open(pdf_path)
            
            for page_num, quoted_text in page_info:
                if 0 <= page_num < len(doc):
                    page = doc[page_num]
                    
                    if quoted_text:
                        page_text = page.get_text()
                        text_instances = self.get_text_instances(page_text, quoted_text)
                        
                        for start, end in text_instances:
                            text_instances = page.search_for(quoted_text)
                            
                            for inst in text_instances:
                                highlight = page.add_highlight_annot(inst)
                                highlight.set_colors({"stroke": (1, 1, 0)})
                                highlight.update()
                    
                    zoom = 2
                    mat = fitz.Matrix(zoom, zoom)
                    pix = page.get_pixmap(matrix=mat)
                    img_bytes = pix.tobytes()
                    screenshots.append(img_bytes)
            
            doc.close()
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF: {str(e)}")
            
        return screenshots

# Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
def create_chat_prompt():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    return PromptTemplate(
        template="""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙÙŠØ¯ Ù„Ø´Ø±ÙƒØ© ØºØ§Ø² Ø§Ù„Ø¨ØµØ±Ø© (BGC). Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù… Ø­ÙˆÙ„ BGC. Ø§ØªØ¨Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø¯Ù‚Ø©:

        1. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©
        2. Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…
        3. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯Ø§Ù‹ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ØµØ±Ø§Ø­Ø©
        4. Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù„ØºØ© Ù…Ù‡Ù†ÙŠØ© ÙˆÙ…Ø­ØªØ±ÙØ©

        Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù…:
        {context}

        Ø§Ù„Ø³Ø¤Ø§Ù„: {input}

        ØªØ°ÙƒØ± Ø£Ù† ØªÙ‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø©:
        1. Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…Ø³ØªÙ†Ø¯Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
        2. Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙˆØ§Ø¶Ø­Ø©
        3. Ù…Ù‡Ù†ÙŠØ© ÙˆÙ…Ù†Ø¸Ù…Ø©
        """,
        input_variables=["context", "input"]
    )

def get_relevant_context(retriever, query, k=3):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø©"""
    docs = retriever.get_relevant_documents(query)
    organized_context = []
    
    for doc in docs[:k]:
        text = clean_text(doc.page_content)
        complete_text = extract_complete_sentences(text)
        if complete_text:
            organized_doc = Document(
                page_content=complete_text,
                metadata={"page": doc.metadata.get("page", "unknown")}
            )
            organized_context.append(organized_doc)
    
    return organized_context

def create_stuff_documents_chain(llm, prompt):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª"""
    return create_stuff_documents_chain(
        llm=llm,
        prompt=prompt
    )

def process_input(input_text, retriever, llm, memory):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    try:
        context = get_relevant_context(retriever, input_text)
        prompt = create_chat_prompt()
        chain = create_retrieval_chain(
            retriever=retriever,
            combine_docs_chain=create_stuff_documents_chain(llm, prompt)
        )
        
        response = chain.invoke({
            "input": input_text,
            "history": memory.load_memory_variables({})["history"]
        })
        
        return {
            "answer": response["answer"],
            "context": context
        }
        
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„: {str(e)}")
        return None

# Ø¯ÙˆØ§Ù„ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
def display_chat_message(message, with_refs=False):
    """Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if with_refs and "references" in message:
            display_references(message["references"])

def display_references(refs):
    """Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„ØµÙˆØ±"""
    if refs and "context" in refs:
        page_info = []
        for doc in refs["context"]:
            page_number = doc.metadata.get("page", "unknown")
            if page_number != "unknown" and str(page_number).isdigit():
                quoted_text = doc.page_content
                page_info.append((int(page_number), quoted_text))

        if page_info:
            sorted_pages = sorted(list(set(page_num for page_num, _ in page_info)))
            page_numbers_str = ", ".join(map(str, sorted_pages))
            st.markdown("---")
            st.markdown(
                f"**{'Ø§Ù„Ù…ØµØ¯Ø±' if interface_language == 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Source'}:** " +
                f"{'ØµÙØ­Ø© Ø±Ù‚Ù…' if interface_language == 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Page'} {page_numbers_str}"
            )

            cols = st.columns(2)
            for idx, (page_num, quoted_text) in enumerate(page_info):
                col_idx = idx % 2
                with cols[col_idx]:
                    screenshots = pdf_searcher.capture_screenshots(pdf_path, [(page_num, quoted_text)])
                    if screenshots:
                        st.image(
                            screenshots[0],
                            use_container_width=True,
                            width=300
                        )
                        st.markdown(
                            f"<div style='text-align: center;'>"
                            f"<p><strong>{'ØµÙØ­Ø©' if interface_language == 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' else 'Page'} {page_num}</strong></p>"
                            f"<p><em>{quoted_text}</em></p>"
                            f"</div>",
                            unsafe_allow_html=True
                        )

def display_response_with_references(response, assistant_response):
    """Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¯ Ù…Ø¹ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹"""
    if not any(phrase in assistant_response for phrase in negative_phrases):
        message = {
            "role": "assistant",
            "content": assistant_response,
            "references": {"context": response["context"]}
        }
        display_chat_message(message, with_refs=True)
    else:
        display_chat_message({
            "role": "assistant",
            "content": assistant_response
        })

# Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
if __name__ == "__main__":
    st.set_page_config(page_title="BGC Assistant", page_icon="ğŸ¤–", layout="wide")
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ session_state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "memory" not in st.session_state:
        st.session_state.memory = ConversationBufferMemory(
            return_messages=True,
            output_key="answer",
            input_key="input"
        )
    
    # ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        interface_language = st.selectbox(
            "Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© / Select Interface Language",
            ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"],
            index=0
        )
        
        # Ø­Ù‚ÙˆÙ„ API
        groq_api_key = st.text_input(
            "Groq API Key",
            type="password",
            help="Enter your Groq API key here"
        )
        
        google_api_key = st.text_input(
            "Google API Key",
            type="password",
            help="Enter your Google API key here"
        )
        
        # Ø­Ù‚Ù„ Ù…Ø³Ø§Ø± PDF
        pdf_path = st.text_input(
            "PDF Path",
            value="",
            help="Enter the path to your PDF file"
        )
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¥Ø°Ø§ ØªÙ… ØªÙˆÙÙŠØ± Ø§Ù„Ù…ÙØ§ØªÙŠØ­
    if groq_api_key and google_api_key and pdf_path:
        os.environ["GOOGLE_API_KEY"] = google_api_key
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª
        llm = ChatGroq(groq_api_key=groq_api_key, model_name="gemma2-9b-it")
        pdf_searcher = PDFSearchAndDisplay()
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª
        if "vectors" not in st.session_state:
            try:
                embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
                st.session_state.vectors = FAISS.load_local("faiss_index", embeddings)
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª: {str(e)}")
        
        # Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        for message in st.session_state.messages:
            if message["role"] == "assistant" and "references" in message:
                display_chat_message(message, with_refs=True)
            else:
                display_chat_message(message)
        
        # Ø­Ù‚Ù„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
        human_input = st.chat_input(
            "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..." if interface_language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Type your question here..."
        )
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
        if human_input:
            user_message = {"role": "user", "content": human_input}
            st.session_state.messages.append(user_message)
            display_chat_message(user_message)
            
            if "vectors" in st.session_state and st.session_state.vectors is not None:
                try:
                    response = process_input(
                        human_input,
                        st.session_state.vectors.as_retriever(),
                        llm,
                        st.session_state.memory
                    )
                    
                    if response:
                        assistant_message = {
                            "role": "assistant",
                            "content": response["answer"],
                            "references": {"context": response["context"]}
                        }
                        st.session_state.messages.append(assistant_message)
                        st.session_state.memory.chat_memory.add_user_message(human_input)
                        st.session_state.memory.chat_memory.add_ai_message(response["answer"])
                        
                        display_response_with_references(response, response["answer"])
                except Exception as e:
                    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
    else:
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØ§ØªÙŠØ­ API ÙˆÙ…Ø³Ø§Ø± Ù…Ù„Ù PDF Ù„Ù„Ø¨Ø¯Ø¡.")
